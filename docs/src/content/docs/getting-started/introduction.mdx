---
title: Introduction
description: Get a high-level overview of the streeteasy-scraper-monorepo project.
---

Welcome to the documentation for the `streeteasy-scraper-monorepo` project! This repository houses a collection of tools designed to automate the process of gathering data from StreetEasy.com and related sources for real estate analysis and other purposes.

At its core, this project aims to provide a flexible and efficient way to collect structured data from property listings on StreetEasy, using a database to manage the scraping process and store the results.

## Key Features

- **Address Seeding:** Initialize your database with a list of target addresses from external sources.
- **Flexible Scraping Methods:** Choose between a synchronous, multi-threaded approach and an asynchronous, webhook-driven workflow for interacting with [BrightData's WebUnlocker](https://brightdata.com/products/web-unlocker).
- **Webhook Integration:** A dedicated service to handle callbacks from BrightData for efficient asynchronous job processing.
- **Dockerized Deployment:** Easily deploy and manage all project components using Docker and Docker Compose.
- **Cloudflared Tunneling:** Securely expose the webhook to the public internet for asynchronous workflows.
- **Structured Data Output:** Scraped data is stored in a PostgreSQL database for easy access and analysis.

## Why Use This Project?

Whether you're a data analyst, researcher, or developer, this project provides a foundation for building datasets of StreetEasy information. Its modular design and use of established technologies make it adaptable for various data collection needs. The inclusion of both synchronous and asynchronous scraping methods allows you to choose the approach that best suits your scale and requirements.

## Technologies Used

The `streeteasy-scraper-monorepo` is built using a modern Python stack and leverages powerful infrastructure tools:

- **Python:** The primary programming language.
- **uv:** A fast Python package installer and resolver.
- **FastAPI:** For building the asynchronous webhook service.
- **SQLAlchemy:** ORM for interacting with the database.
- **PostgreSQL:** The chosen database for storing addresses and scraped data.
- **Docker & Docker Compose:** For containerization and orchestration.
- **Cloudflared:** To expose the webhook publicly via secure tunnels.
- **BrightData WebUnlocker:** A third-party service used for web scraping.

This introduction has provided a brief overview of the project. The following sections will guide you through setting up the synchronous scraping profile, understanding the system's design, and then diving into the details of the asynchronous setup and data usage.

Let's get started with the installation!
